{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# GNN code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <gnn environment setting>\n",
    "\n",
    "# wget https://repo.anaconda.com/archive/Anaconda3-2024.02-1-Linux-x86_64.sh\n",
    "\n",
    "# ls #설치 확인\n",
    "\n",
    "# bash Anaconda3-2024.02-1-Linux-x86_64.sh  # enter 후, 마지막에 yes\n",
    "\n",
    "# source ~/.bashrc\n",
    "\n",
    "# conda list \n",
    "\n",
    "# conda create -n main python=3.10\n",
    "\n",
    "# conda activate main\n",
    "\n",
    "# conda install pytorch torchvision torchaudio pytorch-cuda=12.1 -c pytorch -c nvidia\n",
    "\n",
    "\n",
    "# pip install vllm\n",
    "# pip install --trusted-host pypi.org --trusted-host pypi.python.org --trusted-host files.pythonhosted.org pandas\n",
    "# pip install langchain\n",
    "# pip install langchain-community\n",
    "# pip install langchain-openai\n",
    "# /usr/bin/python -m pip install --upgrade pip\n",
    "# pip install --upgrade transformers\n",
    "# pip3 install openpyxl\n",
    "# pip install git+https://github.com/huggingface/peft\n",
    "# pip install scikit-learn\n",
    "# pip install bitsandbytes\n",
    "# pip install pandas\n",
    "# pip install torch_geometric\n",
    "\n",
    "# pip install pyg_lib torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-2.4.0+cu121.html\n",
    "# /usr/bin/python -m pip install --upgrade pip\n",
    "# pip install --upgrade transformers\n",
    "# pip3 install openpyxl\n",
    "# pip install git+https://github.com/huggingface/peft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch, gc\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()  #메모리 관리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class config():\n",
    "    def __init__(self, i):\n",
    "        self.i = i\n",
    "        self.train_edge_file_path = f'/home/work/lib_data/nghl/kisti/data/0910/240910_18_full_edge(3년후).csv'\n",
    "        self.train_node_file_path = f'/home/work/lib_data/nghl/kisti/data/0910/240910_18_full_node(3년후).csv'\n",
    "        self.test_edge_file_path = f'/home/work/lib_data/nghl/kisti/data/0910/240910_19_full_edge(3년후).csv' \n",
    "        self.test_node_file_path = f'/home/work/lib_data/nghl/kisti/data/0910/240910_19_full_node(3년후).csv'\n",
    "        \n",
    "        self.label_col=25   #입력변수 개수\n",
    "        self.batch_size=1\n",
    "        self.in_dim=25  #col 개수로 맞추어 주기(상동)\n",
    "        self.h_dim=64\n",
    "        self.num_layers=6\n",
    "        self.out_dim=1\n",
    "def seed_everything(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)  # type: ignore\n",
    "    torch.backends.cudnn.deterministic = True  # type: ignore\n",
    "    torch.backends.cudnn.benchmark = True  # type: ignore\n",
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "scaler = RobustScaler()  # 노드에 적용\n",
    "scaler2 = RobustScaler()\n",
    "start=2018\n",
    "\n",
    "# 딕셔너리를 사용하여 edge 데이터를 저장\n",
    "def train_dic():\n",
    "    edges = {}\n",
    "    edges_attr = {}\n",
    "    nodes = {}\n",
    "    labels = {}\n",
    "\n",
    "    for i in range(1):\n",
    "        cfg=config(i)\n",
    "        edge_file_path = cfg.train_edge_file_path\n",
    "        node_file_path = cfg.train_node_file_path\n",
    "        print(edge_file_path)\n",
    "        print(node_file_path) \n",
    "        \n",
    "        edges[f'edge{i}'] = pd.read_csv(edge_file_path)\n",
    "        nodes[f'node{i}'] = pd.read_csv(node_file_path)\n",
    "\n",
    "        labels[f'label{i}'] = pd.DataFrame(nodes[f'node{i}'][['3년매출액증가율']]).apply(pd.to_numeric, errors='coerce')    #label 지정\n",
    "        nodes[f'node{i}'] = nodes[f'node{i}'].drop(columns=['br_num_year', '3년매출액증가율']).apply(pd.to_numeric, errors='coerce')   #drop할 columns 지정\n",
    "        \n",
    "        nodes[f'node{i}'] = scaler.fit_transform(nodes[f'node{i}'])\n",
    "        \n",
    "        edges_attr[f'edge_attr{i}'] = pd.DataFrame(edges[f'edge{i}'].iloc[2,:]).apply(pd.to_numeric, errors='coerce')\n",
    "        edges_attr[f'edge_attr{i}'] = scaler2.fit_transform(edges_attr[f'edge_attr{i}'])\n",
    "\n",
    "        edges[f'edge{i}'] = edges[f'edge{i}'].iloc[:2,:].astype(int)\n",
    "\n",
    "        labels[f'label{i}'] = labels[f'label{i}'].applymap(lambda x: 1 if x >= 72.8 else 0)  #매출액 증가율 기반 label 설정(예측 년도 유망성)\n",
    "        \n",
    "    return edges, edges_attr, nodes, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#데이터 타입 변환\n",
    "edges, edges_attr, nodes, labels = train_dic()\n",
    "\n",
    "for i in range(1):\n",
    "    edges[f'edge{i}'] = edges[f'edge{i}'].values.astype(np.int64)\n",
    "    edges[f'edge{i}'] = torch.from_numpy(edges[f'edge{i}']).long()\n",
    "\n",
    "    nodes[f'node{i}'] = torch.from_numpy(nodes[f'node{i}']).float()\n",
    "    \n",
    "    labels[f'label{i}'] = labels[f'label{i}'].values\n",
    "    labels[f'label{i}'] = torch.from_numpy(labels[f'label{i}']).float()  \n",
    "    \n",
    "    edges_attr[f'edge_attr{i}'] = torch.from_numpy(edges_attr[f'edge_attr{i}']).float() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 추론용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test 차년도\n",
    "# 딕셔너리를 사용하여 edge 데이터를 저장\n",
    "\n",
    "def test_dic2():\n",
    "    testedges = {}\n",
    "    testedges_attr={}\n",
    "    testnodes = {}\n",
    "    testlabels = {}\n",
    "\n",
    "    for i in range(1):\n",
    "        cfg=config(i)\n",
    "        edge_file_path = cfg.test_edge_file_path \n",
    "        node_file_path = cfg.test_node_file_path\n",
    "        print(edge_file_path)\n",
    "        print(node_file_path)        \n",
    "        testedges[f'edge{i}'] = pd.read_csv(edge_file_path)\n",
    "        testnodes[f'node{i}'] = pd.read_csv(node_file_path)\n",
    "        testlabels[f'label{i}'] = pd.DataFrame(testnodes[f'node{i}'][['3년매출액증가율']]).apply(pd.to_numeric, errors='coerce')    #label 지정\n",
    "        testnodes[f'node{i}'] = testnodes[f'node{i}'].drop(columns=['br_num_year','3년매출액증가율']).apply(pd.to_numeric, errors='coerce')    #drop할 columns 지정\n",
    "        \n",
    "        testnodes[f'node{i}'] = scaler.transform(testnodes[f'node{i}'])\n",
    "\n",
    "        testedges_attr[f'edge_attr{i}'] = pd.DataFrame(testedges[f'edge{i}'].iloc[2,:]).apply(pd.to_numeric, errors='coerce')\n",
    "        testedges_attr[f'edge_attr{i}'] = scaler2.transform(testedges_attr[f'edge_attr{i}'])\n",
    "        \n",
    "        testedges[f'edge{i}'] = testedges[f'edge{i}'].iloc[:2,:].astype(int)\n",
    "        \n",
    "        testlabels[f'label{i}'] = testlabels[f'label{i}'].applymap(lambda x: 1 if x >= 72.8 else 0)   #매출액 증가율 기반 label 설정(예측 년도 유망성)\n",
    "        \n",
    "    return testedges,testedges_attr,testnodes,testlabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#데이터 타입 변환\n",
    "testedges2,testedges_attr2,testnodes2,testlabels2 = test_dic2()\n",
    "\n",
    "for i in range(1):\n",
    "    testedges2[f'edge{i}'] = testedges2[f'edge{i}'].values.astype(np.int64)\n",
    "    testedges2[f'edge{i}'] = torch.from_numpy(testedges2[f'edge{i}']).long()\n",
    "\n",
    "    testnodes2[f'node{i}'] = torch.from_numpy(testnodes2[f'node{i}']).float()\n",
    "    \n",
    "    testlabels2[f'label{i}'] = testlabels2[f'label{i}'].values\n",
    "    testlabels2[f'label{i}'] = torch.from_numpy(testlabels2[f'label{i}']).float()\n",
    "      \n",
    "    testedges_attr2[f'edge_attr{i}'] = torch.from_numpy(testedges_attr2[f'edge_attr{i}']).float()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#학습용/테스트용 그래프 데이터 준비\n",
    "import torch_geometric\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "def uselst():\n",
    "    lst=[]\n",
    "    for i in range(1):\n",
    "        lst.append(Data(x=nodes[f'node{i}'], edge_index=edges[f'edge{i}'], edge_attr=edges_attr[f'edge_attr{i}'], y=labels[f'label{i}'])) \n",
    "\n",
    "    testlst2=[]\n",
    "    for i in range(1):\n",
    "        testlst2.append(Data(x=testnodes2[f'node{i}'], edge_index=testedges2[f'edge{i}'], edge_attr=testedges_attr2[f'edge_attr{i}'],y=testlabels2[f'label{i}']))  \n",
    "    \n",
    "    return lst, testlst2\n",
    "lst, testlst2 = uselst()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#데이터 로드 및 배치 구성\n",
    "from torch_geometric.data import Batch\n",
    "from torch_geometric.loader import DataLoader, NeighborLoader\n",
    "\n",
    "test_loader2 = DataLoader(testlst2, batch_size=1, shuffle=False)\n",
    "train_loader = NeighborLoader(Batch.from_data_list(lst), batch_size=256, shuffle=True, num_neighbors=[20, 15], num_workers=2, persistent_workers=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 커스터마이징"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.manual_seed(-1)\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import SAGEConv,GATConv,GATv2Conv\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import f1_score, accuracy_score, recall_score,precision_score\n",
    "from torch_geometric.nn import GIN, GAT\n",
    "cfg = config(1)\n",
    "\n",
    "#모델 정의 및 준비\n",
    "class customSAGEGAT(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, in_channels, hidden_channels,out_channels, heads=8):  #레이어 구성 요소\n",
    "        super(customSAGEGAT,self).__init__()\n",
    "        self.sage1 = SAGEConv(in_channels,hidden_channels)\n",
    "        self.gat1 = GATv2Conv(hidden_channels,hidden_channels, heads=8, edge_dim=1)\n",
    "        self.sage2 = SAGEConv(hidden_channels*heads, hidden_channels)\n",
    "        self.sage3 = SAGEConv(hidden_channels,out_channels)\n",
    "\n",
    "       \n",
    "    def forward(self,data):  #모델 순방향 과정\n",
    "        x, edge_index, edge_attr = data.x, data.edge_index, data.edge_attr\n",
    "\n",
    "        \n",
    "        x = self.sage1(x, edge_index)\n",
    "        x = F.elu(x)\n",
    "        x= F.dropout(x, training=self.training)\n",
    "\n",
    "        x= self.gat1(x = x, edge_index = edge_index, edge_attr = edge_attr)\n",
    "        x = F.elu(x)\n",
    "        x= F.dropout(x, p=0.6,training=self.training)\n",
    "        \n",
    "        x = self.sage2(x, edge_index)\n",
    "        x = F.elu(x)\n",
    "        x= F.dropout(x,  p=0.6,training=self.training)\n",
    "\n",
    "        x = self.sage3(x, edge_index)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = customSAGEGAT(in_channels=cfg.in_dim,hidden_channels=128,out_channels=1).to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#학습 함수 정의\n",
    "def train(loader):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for i,data in enumerate(loader,0): \n",
    "        \n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        out = model(data)\n",
    "        loss = criterion(out, data.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    return total_loss/ len(loader)\n",
    "    \n",
    "#테스트 함수 정의\n",
    "def test(loader):\n",
    "    model.eval()\n",
    "    predict = list()\n",
    "    actual = list()\n",
    "    logit=list()\n",
    "    total_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for _, data in enumerate(loader,0):\n",
    "            data = data.to(device)\n",
    "            out = model(data)\n",
    "            loss2 = criterion(out, data.y)\n",
    "            total_loss += loss2.item()\n",
    "\n",
    "            m = nn.Sigmoid()   #시그모이드 함수를 적용하여 logit을 0~1 사이의 값으로 변환\n",
    "            preds = (m(out)>0.5).float().cpu().numpy()\n",
    "            y = data.y.cpu().numpy()\n",
    "            logit_batch = m(out).cpu().numpy()\n",
    "            \n",
    "            predict.append(preds)\n",
    "            logit.append(logit_batch)\n",
    "            actual.append(y)\n",
    "    \n",
    "    #평가 지표 계산산\n",
    "    predictions, actuals = vstack(predict), vstack(actual)\n",
    "    acc = accuracy_score(actuals, predictions)\n",
    "    f1  = f1_score(actuals, predictions)\n",
    "    rec  = recall_score(actuals, predictions, zero_division=1)\n",
    "    prec  = precision_score(actuals, predictions, zero_division=1)\n",
    "\n",
    "    return total_loss / len(loader), acc, f1, rec, prec, logit, actual, predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from numpy import vstack\n",
    "\n",
    "#손실 함수 및 옵티마이저 설정\n",
    "criterion = torch.nn.BCEWithLogitsLoss().to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.001)\n",
    "\n",
    "#변수 초기화\n",
    "best_acc = 0\n",
    "best_epoch = 0\n",
    "best_f1 = 0\n",
    "best_recall = 0\n",
    "best_precision = 0\n",
    "\n",
    "#early stopping 설정\n",
    "early_stopping_epochs = 30\n",
    "early_stop_counter = 0\n",
    "best_loss = float('inf')\n",
    "\n",
    "#학습 루프 실행\n",
    "for epoch in tqdm(range(80)):\n",
    "    loss = train(train_loader)\n",
    "    print(loss)\n",
    "    torch.save(model.state_dict(), f'/home/work/lib_data/nghl/kisti/model_save/full_0910_classification.pth')  # 모델 가중치 저장"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 추론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('/home/work/lib_data/nghl/kisti/model_save/full_0910_classification.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_node = pd.read_csv('/home/work/lib_data/nghl/kisti/data/0910/240910_18_full_node(3년후).csv')\n",
    "test_node = pd.read_csv('/home/work/lib_data/nghl/kisti/data/0910/240910_19_full_node(3년후).csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 차년도 추론\n",
    "for epoch in tqdm(range(1)):\n",
    "\n",
    "    loss2, acc, f1, rec, prec, logit, actual, predict  = test(test_loader2)\n",
    "\n",
    "    print(f' Test loss: {loss2:.3f} | Test acc: {acc:.3f} | Test f1: {f1:.3f} | Test rec: {rec:.3f} | Test prec : {prec:.3f} ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'acc': [acc],'f1':[f1],'recall':[rec],'precision':[prec]}).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(logit[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#logit값을 붙인 데이터 저장\n",
    "combined_df_test = pd.concat([pd.DataFrame(logit[0],columns=['logit']),test_node],axis=1)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
